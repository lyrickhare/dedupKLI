{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Fri Apr 24 20:01:19 2020\n",
    "\n",
    "@author: Kshitija Surange\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "from pytesseract import Output\n",
    "import re\n",
    "import os\n",
    "from scipy import ndimage\n",
    "import face_recognition\n",
    "import math\n",
    "import numpy as np\n",
    "class Aadhaar_Card():\n",
    "    #Constructor\n",
    "    def __init__(self,config = {'orient' : True,'skew' : True,'crop': True,'contrast' : True,'psm': [3,4,6],'mask_color': (0, 165, 255), 'brut_psm': [6]}):\n",
    "        self.config = config\n",
    "    # Validates Aadhaar card numbers using Verhoeff Algorithm.\n",
    "    # Fails if the fake number is generated using same Algorithm.\n",
    "    def validate(self,aadhaarNum):\n",
    "        \n",
    "        mult = [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9], [1, 2, 3, 4, 0, 6, 7, 8, 9, 5], [2, 3, 4, 0, 1, 7, 8, 9, 5, 6],\n",
    "            [3, 4, 0, 1, 2, 8, 9, 5, 6, 7], [4, 0, 1, 2, 3, 9, 5, 6, 7, 8], [5, 9, 8, 7, 6, 0, 4, 3, 2, 1],\n",
    "            [6, 5, 9, 8, 7, 1, 0, 4, 3, 2], [7, 6, 5, 9, 8, 2, 1, 0, 4, 3], [8, 7, 6, 5, 9, 3, 2, 1, 0, 4],\n",
    "            [9, 8, 7, 6, 5, 4, 3, 2, 1, 0]]\n",
    "\n",
    "        perm = [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9], [1, 5, 7, 6, 2, 8, 3, 0, 9, 4], [5, 8, 0, 3, 7, 9, 6, 1, 4, 2],\n",
    "            [8, 9, 1, 6, 0, 4, 3, 5, 2, 7], [9, 4, 5, 3, 1, 2, 6, 8, 7, 0], [4, 2, 8, 6, 5, 7, 3, 9, 0, 1],\n",
    "            [2, 7, 9, 3, 8, 0, 6, 4, 1, 5], [7, 0, 4, 6, 9, 1, 3, 2, 5, 8]]\n",
    "\n",
    "\n",
    "        try:\n",
    "            i = len(aadhaarNum)\n",
    "            j = 0\n",
    "            x = 0\n",
    "\n",
    "            while i > 0:\n",
    "                i -= 1\n",
    "                x = mult[x][perm[(j % 8)][int(aadhaarNum[i])]]\n",
    "                j += 1\n",
    "            if x == 0:\n",
    "                return 1 \n",
    "            else:\n",
    "                return 0 \n",
    "\n",
    "        except ValueError:\n",
    "            return 0 \n",
    "        except IndexError:\n",
    "            return 0 \n",
    "        \n",
    "\n",
    "        \n",
    "    def extract(self, path):  #(\"path of input image\")\n",
    "        self.image_path = path\n",
    "        self.read_image_cv()\n",
    "        if self.config['orient']:\n",
    "            self.cv_img = self.rotate(self.cv_img)\n",
    "            \n",
    "        '''\n",
    "\n",
    "            try:\n",
    "                self.cv_img = self.rotate(self.cv_img)\n",
    "            except:\n",
    "                self.read_image_pil()\n",
    "            else:\n",
    "                self.cv_img.save('1_temp.png')\n",
    "                self.pil_img = Image.open('1_temp.png')     \n",
    "                os.remove('1_temp.png')\n",
    "        \n",
    "        self.pil_img = self.pil_img.convert('RGBA')\n",
    "        '''\n",
    "            \n",
    "        if self.config['skew']:\n",
    "            print(\"skewness correction not available\")\n",
    "        \n",
    "        if self.config['crop']:\n",
    "            print(\"Smart Crop not available\")\n",
    "        \n",
    "        if self.config['contrast']:\n",
    "            self.cv_img  = self.contrast_image(self.cv_img)\n",
    "            #self.pil_img  = self.contrast_image(self.pil_img )\n",
    "            print(\"correcting contrast\")\n",
    "            \n",
    "        aadhaars = set()\n",
    "        for i in range(len(self.config['psm'])):\n",
    "            t = self.text_extractor(self.cv_img,self.config['psm'][i])\n",
    "            anum = self.is_aadhaar_card(t)\n",
    "            uid = self.find_uid(t)\n",
    "\n",
    "\n",
    "            if anum != \"Not Found\" and len(uid) == 0:\n",
    "                if len(anum) - anum.count(' ') == 12:\n",
    "                   aadhaars.add(anum.replace(\" \", \"\"))\n",
    "            if anum == \"Not Found\" and len(uid) != 0:\n",
    "\n",
    "                aadhaars.add(uid[0].replace(\" \", \"\"))\n",
    "            if anum != \"Not Found\" and len(uid) != 0:\n",
    "                if len(anum) - anum.count(' ') == 12:\n",
    "                   aadhaars.add(anum.replace(\" \", \"\"))\n",
    "                #print(uid[0].strip())\n",
    "                aadhaars.add(uid[0].replace(\" \", \"\"))\n",
    "\n",
    "        return list(aadhaars)\n",
    "    \n",
    "    def mask_image(self, path, write, aadhaar_list):\n",
    "        #print(\"Read Path => \", path, \" write path => \",write, \"aadhaar list =>\",aadhaar_list)\n",
    "        self.mask_count = 0\n",
    "        self.mask = cv2.imread(str(path), cv2.IMREAD_COLOR)\n",
    "        for j in range(len(self.config['psm'])):\n",
    "            for i in range(len(aadhaar_list)):\n",
    "                #print(\" Runing mode: Aadhaar number:\",aadhaar_list[i],\" PSM => \",self.config['psm'][j])\n",
    "                if (self.mask_aadhaar(aadhaar_list[i],write,self.config['psm'][j]))>0:\n",
    "                    self.mask_count = self.mask_count + 1\n",
    "                #print(\" :\\/ \",self.mask_count)\n",
    "            \n",
    "        #print(\"Final Mask Count =>\",self.mask_count)\n",
    "        cv2.imwrite(write,self.mask)\n",
    "        return self.mask_count\n",
    "    \n",
    "    def mask_aadhaar(self, uid, out_path, psm):\n",
    "        d = self.box_extractor(self.mask, psm)\n",
    "        n_boxes = len(d['level'])\n",
    "        color = self.config['mask_color'] #BGR\n",
    "        count_of_match = 0\n",
    "        for i in range(n_boxes):\n",
    "            string = d['text'][i].strip()\n",
    "            if string.isdigit() and string in uid and len(string)>=2:\n",
    "                (x, y, w, h) = (d['left'][i], d['top'][i], d['width'][i], d['height'][i])\n",
    "                cv2.rectangle(self.mask, (x, y), (x + w, y + h), color, cv2.FILLED)\n",
    "                count_of_match = count_of_match + 1 \n",
    "            else:\n",
    "                count_of_match = count_of_match + 0\n",
    "        return count_of_match \n",
    "\n",
    "    def read_image_cv(self):\n",
    "        self.cv_img = cv2.imread(str(self.image_path), cv2.IMREAD_COLOR)\n",
    "        \n",
    "    '''\n",
    "    def read_image_pil(self):\n",
    "        self.pil_img = Image.open(self.image_path)\n",
    "    '''\n",
    "        \n",
    "    def mask_nums(self, input_file, output_file):\n",
    "        img = cv2.imread(str(input_file), cv2.IMREAD_COLOR)\n",
    "        for i in range(len(self.config['brut_psm'])):      #'brut_psm': [6]\n",
    "            d = self.box_extractor(img,self.config['brut_psm'][i])\n",
    "            n_boxes = len(d['level'])\n",
    "            color = self.config['mask_color']  #BGR\n",
    "            for i in range(n_boxes):\n",
    "                string = d['text'][i].strip()\n",
    "                if string.isdigit() and len(string)>=1:\n",
    "                    #print('Number to be Masked =>',string)\n",
    "                    (x, y, w, h) = (d['left'][i], d['top'][i], d['width'][i], d['height'][i])\n",
    "                    #print(\"Rectangles =>\",(x, y, w, h))\n",
    "                    cv2.rectangle(img, (x, y), (x + w, y + h), color, cv2.FILLED)\n",
    "\n",
    "        cv2.imwrite(output_file,img)\n",
    "\n",
    "        return \"Done\"\n",
    "    \n",
    "    def rotate_only(self, img, angle_in_degrees):\n",
    "        self.img = img\n",
    "        self.angle_in_degrees = angle_in_degrees\n",
    "        rotated = ndimage.rotate(self.img, self.angle_in_degrees)\n",
    "        return rotated\n",
    "    \n",
    "    def is_image_upside_down(self, img):\n",
    "        self.img = img\n",
    "        face_locations = face_recognition.face_locations(self.img)\n",
    "        encodings = face_recognition.face_encodings(self.img, face_locations)\n",
    "        image_is_upside_down = (len(encodings) == 0)\n",
    "        return image_is_upside_down\n",
    "    \n",
    "    ''' \n",
    "    def save_image(self, img):\n",
    "        self.img = img\n",
    "        cv2.imwrite('orientation_corrected.jpg', self.img)\n",
    "\n",
    "           \n",
    "    def display(self, img, frameName=\"OpenCV Image\"):\n",
    "        self.img = img\n",
    "        self.frameName = frameName\n",
    "        h, w = self.img.shape[0:2]   \n",
    "        neww = 800\n",
    "        newh = int(neww*(h/w))\n",
    "        self.img = cv2.resize(self.img, (neww, newh))\n",
    "        cv2.imshow(self.frameName, self.img)\n",
    "        cv2.waitKey(0)\n",
    "    '''\n",
    "    \n",
    "    # Corrects orientation of image using tesseract OSD if rotation Angle is < 100.\n",
    "    def rotate(self,img):\n",
    "        #def orientation_correction(img): #, save_image = False):\n",
    "        # GrayScale Conversion for the Canny Algorithm \n",
    "        self.img = img\n",
    "        img_gray = cv2.cvtColor(self.img, cv2.COLOR_BGR2GRAY) \n",
    "        #self.display(img_gray)\n",
    "        # Canny Algorithm for edge detection was developed by John F. Canny not Kennedy!! :)\n",
    "        img_edges = cv2.Canny(img_gray, 100, 100, apertureSize=3)\n",
    "        #self.display(img_edges)\n",
    "        # Using Houghlines to detect lines\n",
    "        lines = cv2.HoughLinesP(img_edges, 1, math.pi / 180.0, 100, minLineLength=100, maxLineGap=5)\n",
    "        img_copy = self.img.copy()\n",
    "        for x in range(0, len(lines)):\n",
    "            for x1,y1,x2,y2 in lines[x]:\n",
    "                cv2.line(img_copy,(x1,y1),(x2,y2),(0,255,0),2)\n",
    "        #cv2.imshow('hough',img_copy)\n",
    "        #cv2.waitKey(0)\n",
    "        \n",
    "        angles = []\n",
    "        for x1, y1, x2, y2 in lines[0]:\n",
    "            angle = math.degrees(math.atan2(y2 - y1, x2 - x1))\n",
    "            angles.append(angle)\n",
    "        \n",
    "        # Getting the median angle\n",
    "        median_angle = np.median(angles)\n",
    "        # Rotating the image with this median angle\n",
    "        img_rotated = self.rotate_only(self.img, median_angle)\n",
    "        #self.display(img_rotated)\n",
    "        \n",
    "        if self.is_image_upside_down(img_rotated):\n",
    "            print(\"rotate to 180 degree\")\n",
    "            angle = -180\n",
    "            img_rotated_final = self.rotate_only(img_rotated, angle)\n",
    "            #self.save_image(img_rotated_final)\n",
    "            #self.display(img_rotated_final)\n",
    "            if self.is_image_upside_down(img_rotated_final):\n",
    "                print(\"Kindly check the uploaded image, face encodings still not found!\")\n",
    "                return img_rotated\n",
    "            else:\n",
    "                print(\"image is now straight\")\n",
    "                return img_rotated_final\n",
    "        else:\n",
    "            #self.display(img_rotated)\n",
    "            print(\"image is straight\")\n",
    "            return img_rotated\n",
    "\n",
    "        \n",
    "    # Turns images BnW using pixels, didn't have much success with this and skipped in final production \n",
    "    def contrast_image(self, img):\n",
    "        self.img = img\n",
    "        gray = cv2.cvtColor(self.img, cv2.COLOR_BGR2GRAY)\n",
    "        #gray = cv2.bitwise_not(gray)\n",
    "        thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n",
    "        #self.display(thresh)\n",
    "        return thresh\n",
    "    \n",
    "    # Extracts Texts from images\n",
    "    def text_extractor(self, img, psm):\n",
    "        config  = ('-l eng --oem 3 --psm '+ str(psm))\n",
    "        t = pytesseract.image_to_string(img, lang='eng', config = config)\n",
    "        return t\n",
    "    # Extracts Texts and their bounding boxes in form of txt\n",
    "    def box_extractor(self, img, psm):\n",
    "        config  = ('-l eng --oem 3 --psm '+ str(psm))\n",
    "        t = pytesseract.image_to_data(img, lang='eng', output_type=Output.DICT, config=config) \n",
    "        return t\n",
    "\n",
    "    def find_uid(self,text2):\n",
    "        # Searching for UID\n",
    "        uid = set()\n",
    "        try:\n",
    "            newlist = []\n",
    "            for xx in text2.split('\\n'):\n",
    "                newlist.append(xx)\n",
    "            newlist = list(filter(lambda x: len(x) > 12, newlist))\n",
    "            for no in newlist:\n",
    "                #print(no)\n",
    "                if re.match(\"^[0-9 ]+$\", no):\n",
    "                    uid.add(no)\n",
    "\n",
    "        except Exception:\n",
    "            pass\n",
    "        return list(uid)\n",
    "    \n",
    "    #Function to validate if an image contains text showing its an aadhaar card\n",
    "    def is_aadhaar_card(self, text):\n",
    "               res=text.split()\n",
    "               aadhaar_number=''\n",
    "               for word in res:\n",
    "                  if len(word) == 4 and word.isdigit():\n",
    "                      aadhaar_number=aadhaar_number  + word + ' '\n",
    "               if len(aadhaar_number)>=14:\n",
    "                   return aadhaar_number\n",
    "                   \n",
    "               else:\n",
    "\n",
    "                    return \"Not Found\"\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = Aadhaar_Card()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytesseract.pytesseract.tesseract_cmd = 'C:/Program Files/Tesseract-OCR/tesseract.exe'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image is straight\n",
      "skewness correction not available\n",
      "Smart Crop not available\n",
      "correcting contrast\n"
     ]
    }
   ],
   "source": [
    "aadhaar_list = obj.extract(\"aadharlkf.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag = obj.mask_image(\"aadharlkf.png\", \"aadharlkf_masked.png\", aadhaar_list) #supported types (png, jpeg, jpg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
